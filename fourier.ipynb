{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = 9, 6\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sample_data\n",
    "\n",
    "np.random.seed(0)\n",
    "N_train = 2 ** 10; N_test = 0\n",
    "N = N_train + N_test\n",
    "train = np.arange(N_train); test = np.arange(N_test) + N_train\n",
    "n_min = 16; n_max = n_min\n",
    "\n",
    "X, w = sample_data.periodic(N, n_min, n_max, t_max=2*np.pi, even=True,\n",
    "                            A_shape=1., noise_sigma=1e-0, w_min=0.1, w_max=1.)\n",
    "M = X[:, :, 1:2]\n",
    "print(M.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "import pywt\n",
    "from scipy.fftpack import fft, dct\n",
    "\n",
    "Y = dct(M)[:, :, :]\n",
    "#Y = np.array([pywt.wavedec(m, pywt.Wavelet('db4'))\n",
    "#              for m in M]).reshape(M.shape)\n",
    "#A = np.random.normal(size=n_min ** 2).reshape((n_min, n_min))\n",
    "#Y = (M[:, :, 0] @ A)\n",
    "\n",
    "print(M.shape, Y.shape)\n",
    "Y = Y.reshape(M.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 3, sharey=False)\n",
    "for i in range(3):\n",
    "    ax[0, i].plot(X[i][:, 0], M[i, :, 0], 'o')\n",
    "    ax[0, i].set(xlabel=\"t\", ylabel=\"y\")\n",
    "    ax[1, i].plot(X[i][:, 0], Y[i, :], 'o')\n",
    "    ax[1, i].set(xlabel=\"t\", ylabel=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback\n",
    "from IPython.core.display import clear_output\n",
    "\n",
    "class ClearOutput(Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.layers import (Input, Dense, TimeDistributed, Activation,\n",
    "                          LSTM, Dropout, merge, Reshape, Flatten,\n",
    "                          RepeatVector, ActivityRegularization,\n",
    "                          Convolution1D, MaxPooling1D, Lambda)\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.regularizers import l1, activity_l1\n",
    "from keras import metrics\n",
    "from keras.callbacks import ProgbarLogger, TensorBoard\n",
    "from IPython.display import clear_output, display\n",
    "\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=tf.GPUOptions(\n",
    "            per_process_gpu_memory_fraction=0.2)))\n",
    "K.set_session(sess)\n",
    "\n",
    "#lstm_size = 128\n",
    "#num_layers = 4\n",
    "#lr = 4e-3\n",
    "#drop_frac = 0.2\n",
    "#run = \"lstm_{:03d}_{}_{:1.0e}_drop{}\".format(lstm_size, num_layers, lr, drop_frac).replace('e-', 'm').replace('.', '')\n",
    "#print(run)\n",
    "#model = Sequential()\n",
    "#model.add(LSTM(lstm_size, input_shape=(n_max, 1), return_sequences=True))\n",
    "#for i in range(1, num_layers):\n",
    "#    model.add(Dropout(drop_frac))\n",
    "#    model.add(LSTM(lstm_size, return_sequences=(i != num_layers - 1)))\n",
    "#model.add(Dense(Y.shape[1], activation='linear'))\n",
    "#adam = Adam(lr=lr)\n",
    "#model.compile(optimizer=adam, loss='mse', metrics=[])\n",
    "\n",
    "#model = Sequential()\n",
    "#model.add(Convolution1D(conv_size, length, border_mode='same', input_shape=(n_max, 1)))\n",
    "#model.add(MaxPooling1D())\n",
    "#model.add(Flatten())\n",
    "#model.add(Dense(Y.shape[1], activation='linear'))\n",
    "#adam = Adam(lr=lr)\n",
    "#model.compile(optimizer=adam, loss='mse', metrics=[])\n",
    "#run = \"conv_max_{}_{}_{:1.0e}\".format(conv_size, length, lr).replace('e-', 'm')\n",
    "#print(run)\n",
    "\n",
    "# Zero out odd/even components\n",
    "zero_odd = Lambda(lambda x: x * np.tile([0, 1], int(x.get_shape()[-1].value / 2)))\n",
    "zero_even = Lambda(lambda x: x * np.tile([1, 0], int(x.get_shape()[-1].value / 2)))\n",
    "# Pass everything through\n",
    "#zero_odd = Lambda(lambda x: x * np.tile([1, 1], int(x.get_shape()[-1].value / 2)))\n",
    "#zero_even = Lambda(lambda x: x * np.tile([1, 1], int(x.get_shape()[-1].value / 2)))\n",
    "\n",
    "dense_size = n_max\n",
    "lr = 8e-2\n",
    "rho = 0.0\n",
    "input = Input(shape=(n_max,))\n",
    "dense_o = Dense(dense_size / 2, bias=False, W_regularizer=l1(rho))(zero_odd(input))\n",
    "dense_e = Dense(dense_size / 2, bias=False, W_regularizer=l1(rho))(zero_even(input))\n",
    "\n",
    "dense_oo = Dense(dense_size / 4, bias=False)(zero_odd(dense_o))\n",
    "dense_oe = Dense(dense_size / 4, bias=False)(zero_odd(dense_e))\n",
    "dense_eo = Dense(dense_size / 4, bias=False)(zero_even(dense_o))\n",
    "dense_ee = Dense(dense_size / 4, bias=False)(zero_even(dense_e))\n",
    "\n",
    "dense_ooo = Dense(dense_size / 8, bias=False)(zero_odd(dense_oo))\n",
    "dense_ooe = Dense(dense_size / 8, bias=False)(zero_odd(dense_oe))\n",
    "dense_oeo = Dense(dense_size / 8, bias=False)(zero_odd(dense_eo))\n",
    "dense_oee = Dense(dense_size / 8, bias=False)(zero_odd(dense_ee))\n",
    "dense_eoo = Dense(dense_size / 8, bias=False)(zero_even(dense_oo))\n",
    "dense_eoe = Dense(dense_size / 8, bias=False)(zero_even(dense_oe))\n",
    "dense_eeo = Dense(dense_size / 8, bias=False)(zero_even(dense_eo))\n",
    "dense_eee = Dense(dense_size / 8, bias=False)(zero_even(dense_ee))\n",
    "\n",
    "merged_1 = merge([dense_o, dense_e],\n",
    "#merged_1 = merge([dense_ooo, dense_ooe, dense_oeo, dense_oee,\n",
    "#                  dense_eoo, dense_eoe, dense_eeo, dense_eee], \n",
    "                 mode='concat')\n",
    "output = Dense(n_max, bias=False)(merged_1)\n",
    "model = Model(input, output)\n",
    "sgd = SGD(lr=lr)\n",
    "model.compile(optimizer=sgd, loss='mse', metrics=[metrics.mean_squared_error])\n",
    "run = \"split_{}_{:1.0e}\".format(dense_size, lr).replace('e-', 'm')\n",
    "print(run)\n",
    "\n",
    "log_dir = os.path.expanduser('~/Dropbox/Documents/timeflow/keras_logs/fourier/{}'.format(run))\n",
    "!rm -rf $log_dir\n",
    "history = model.fit(M[train, :, 0], Y[train, :, 0],\n",
    "                     nb_epoch=5000, batch_size=N_train, validation_split=0.0,\n",
    "                     callbacks=[TensorBoard(log_dir=log_dir, write_graph=False),\n",
    "                                ProgbarLogger(), ClearOutput(),\n",
    "                               ],\n",
    "#                    verbose=0\n",
    "                   )\n",
    "model.save_weights(os.path.join(log_dir, 'raw.h5'), overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.utils.visualize_util import model_to_dot\n",
    "from IPython.display import SVG\n",
    "\n",
    "model_dot = model_to_dot(model).create(prog='dot', format='svg')\n",
    "print('{} MB'.format(model.count_params() * np.dtype('float32').itemsize / 1e6))\n",
    "print(model.summary())\n",
    "SVG(model_dot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W = model.get_weights()\n",
    "[np.mean(np.abs(W[i]) >= 1e-3) for i in range(len(W))]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## log_dir = os.path.expanduser('~/Dropbox/Documents/timeflow/keras_logs/fourier/{}'.format(run))\n",
    "!rm -rf $log_dir\n",
    "#if os.path.exists(log_dir):\n",
    "#    raise Exception(\"Log directory already exists, not overwriting\")\n",
    "history = model.fit(M[train, :, 0], Y[train], \n",
    "                     nb_epoch=100, batch_size=5000, validation_split=0.2,\n",
    "                     callbacks=[ProgbarLogger(), TensorBoard(log_dir=log_dir, write_graph=False),\n",
    "                                ClearOutput()])\n",
    "model.save_weights(os.path.join(log_dir, 'weights.h5'), overwrite=True)\n",
    "#clear_output()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
