{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DOWNLOAD_DIR = \"data\"\n",
    "!wget -nc -P $DOWNLOAD_DIR \"https://archive.ics.uci.edu/ml/machine-learning-databases/00240/UCI HAR Dataset.zip\"\n",
    "!wget -nc -P $DOWNLOAD_DIR \"https://archive.ics.uci.edu/ml/machine-learning-databases/00240/UCI HAR Dataset.names\"\n",
    "!unzip -oq -d $DOWNLOAD_DIR \"$DOWNLOAD_DIR/UCI HAR Dataset.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "DATA_DIR = os.path.join(DOWNLOAD_DIR, \"UCI HAR Dataset\")\n",
    "\n",
    "X_train_list = [np.loadtxt(f) for f in glob.glob(os.path.join(DATA_DIR, \"train\", \"Inertial Signals\", \"*\"))]\n",
    "X_train = np.array(X_train_list).transpose((1, 0, 2))\n",
    "y_train = np.loadtxt(os.path.join(DATA_DIR, \"train\", \"y_train.txt\")) - 1\n",
    "Y_train = to_categorical(y_train)\n",
    "X_test_list = [np.loadtxt(f) for f in glob.glob(os.path.join(DATA_DIR, \"test\", \"Inertial Signals\", \"*\"))]\n",
    "X_test = np.array(X_test_list).transpose((1, 0, 2))\n",
    "y_test = np.loadtxt(os.path.join(DATA_DIR, \"test\", \"y_test.txt\")) - 1\n",
    "Y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback\n",
    "from IPython.core.display import clear_output\n",
    "\n",
    "class ClearOutput(Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.layers import Input, Dense, LSTM, Dropout\n",
    "from keras.regularizers import l2\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ProgbarLogger, TensorBoard\n",
    "\n",
    "n_hidden = 32\n",
    "lr = 0.0025\n",
    "lambda_l2 = 0.0015\n",
    "nb_epoch = 300\n",
    "batch_size = 1500\n",
    "\n",
    "input_shape = X_train.shape[1:]\n",
    "output_shape = Y_train.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(n_hidden, input_shape=input_shape, W_regularizer=l2(lambda_l2), return_sequences=True))\n",
    "model.add(LSTM(n_hidden, W_regularizer=l2(lambda_l2)))\n",
    "model.add(Dense(output_shape, activation='softmax'))\n",
    "model.compile(optimizer=Adam(lr=lr), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(X_train, Y_train, nb_epoch=nb_epoch, batch_size=batch_size,\n",
    "                    callbacks=[ProgbarLogger(), TensorBoard(log_dir='log'), ClearOutput()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"LSTM test accuracy: {}\".format(np.mean(np.argmax(model.predict(X_test), axis=1) == y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "import cesium as cs\n",
    "\n",
    "features_to_use = [f for f in cs.features.GENERAL_FEATS if 'period' not in f and 'flux' not in f]\n",
    "fset_train = cs.featurize.featurize_time_series(None, [X_i for X_i in X_train], None, \n",
    "                                                features_to_use=features_to_use,\n",
    "                                                targets=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "param_grid = {'n_estimators': [256, 512],\n",
    "              'criterion': ['mse', 'mae'],\n",
    "              'max_features': [0.165, 0.28, 0.33, 0.38, 0.43, 0.5, 0.667]\n",
    "              }\n",
    "\n",
    "cs_model = cs.build_model.build_model_from_featureset(fset_train, model_type='RandomForestClassifier',\n",
    "                                                      params_to_optimize=param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "fset_test = cs.featurize.featurize_time_series(None, [X_i for X_i in X_test], None, \n",
    "                                               features_to_use=features_to_use,\n",
    "                                               targets=y_test)\n",
    "cs_pred = cs.predict.model_predictions(fset_test, cs_model, return_probs=False)\n",
    "print(\"Cesium test accuracy: {}\".format(np.mean(cs_pred.prediction == y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Cesium test accuracy: {}\".format(np.mean(cs_pred.prediction.values == y_test)))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:deep]",
   "language": "python",
   "name": "conda-env-deep-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
