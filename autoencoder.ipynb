{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = 9, 6\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "N = 5000\n",
    "n_min = 100\n",
    "\n",
    "filenames = glob.glob('./data/survey_lcs/*')\n",
    "lengths = {f: sum(1 for line in open(f)) for f in filenames}\n",
    "filenames = [f for f in filenames if lengths[f] >= n_min]\n",
    "filenames = sorted(filenames, key=lambda f: lengths[f])\n",
    "\n",
    "X_list = [np.loadtxt(f, delimiter=',') for f in filenames[:N]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import keras_util as ku\n",
    "from autoencoder import uneven_gru_autoencoder\n",
    "\n",
    "model_type = 'gru'\n",
    "size = 64\n",
    "num_layers = 2\n",
    "drop_frac = 0.5\n",
    "lr = 0.001\n",
    "nb_epoch = 100\n",
    "batch_size = 100\n",
    "gpu_frac = 0.48\n",
    "gpu_id = 0\n",
    "loss = 'mse'\n",
    "sim_type = 'survey_lcs'\n",
    "\n",
    "model_dict = {'gru': uneven_gru_autoencoder}\n",
    "K.set_session(ku.limited_memory_session(gpu_frac, gpu_id))\n",
    "X = pad_sequences(X_list, value=-1., dtype='float')\n",
    "model = model_dict[model_type](input_len=X.shape[-1], aux_input_len=2, n_step=X.shape[1],\n",
    "                               size=size, num_layers=num_layers, drop_frac=drop_frac)\n",
    "                                    \n",
    "run = \"{}_{:03d}_x{}_{:1.0e}_drop{}\".format(model_type, size, num_layers, lr,\n",
    "                                            int(100 * drop_frac)).replace('e-', 'm')\n",
    "if 'conv' in run:\n",
    "    run += '_f{}'.format(nfilter)\n",
    "\n",
    "history = ku.train_and_log({'main_input': X, 'aux_input': X[:, :, [0, 2]]}, X[:, :, 1:2],\n",
    "                            run, model, lr=lr, nb_epoch=nb_epoch, batch_size=batch_size,\n",
    "                           loss=loss, sim_type=sim_type)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
