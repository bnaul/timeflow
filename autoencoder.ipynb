{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = 9, 6\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "N = 5000\n",
    "n_min = 100\n",
    "\n",
    "filenames = glob.glob('./data/survey_lcs/*')\n",
    "lengths = {f: sum(1 for line in open(f)) for f in filenames}\n",
    "filenames = [f for f in filenames if lengths[f] >= n_min]\n",
    "filenames = sorted(filenames, key=lambda f: lengths[f])\n",
    "\n",
    "X_list = [np.loadtxt(f, delimiter=',') for f in filenames[:N]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "/Users/brettnaul/Dropbox/Documents/timeflow/keras_logs/survey_lcs/gru_064_x2_1m03_drop50\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Error when checking model input: expected aux_input to have shape (None, 4108, 2) but got array with shape (5000, 2, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-ccce930aff6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m history = ku.train_and_log({'main_input': X, 'aux_input': X[:, [0, 2]]}, X[:, 1:2],\n\u001b[1;32m     28\u001b[0m                             \u001b[0mrun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                            loss=loss, sim_type=sim_type)\n\u001b[0m",
      "\u001b[0;32m/Users/brettnaul/Dropbox/Documents/timeflow/keras_util.py\u001b[0m in \u001b[0;36mtrain_and_log\u001b[0;34m(X, Y, run, model, nb_epoch, batch_size, lr, loss, sim_type, metrics, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m                             validation_split=0.2, callbacks=[ProgbarLogger(),\n\u001b[1;32m     35\u001b[0m                                                              TensorBoard(log_dir=log_dir,\n\u001b[0;32m---> 36\u001b[0;31m                                                                          write_graph=False)])\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'weights.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/brettnaul/Dropbox/Documents/keras/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight)\u001b[0m\n\u001b[1;32m   1030\u001b[0m                                                            \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m                                                            \u001b[0mcheck_batch_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m                                                            batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1033\u001b[0m         \u001b[0;31m# prepare validation data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/brettnaul/Dropbox/Documents/keras/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_dim, batch_size)\u001b[0m\n\u001b[1;32m    957\u001b[0m                                    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternal_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m                                    \u001b[0mcheck_batch_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 959\u001b[0;31m                                    exception_prefix='model input')\n\u001b[0m\u001b[1;32m    960\u001b[0m         y = standardize_input_data(y, self.output_names,\n\u001b[1;32m    961\u001b[0m                                    \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/brettnaul/Dropbox/Documents/keras/keras/engine/training.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_dim, exception_prefix)\u001b[0m\n\u001b[1;32m    106\u001b[0m                                         \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m                                         \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m                                         str(array.shape))\n\u001b[0m\u001b[1;32m    109\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Error when checking model input: expected aux_input to have shape (None, 4108, 2) but got array with shape (5000, 2, 3)"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import keras_util as ku\n",
    "from autoencoder import uneven_gru_autoencoder\n",
    "\n",
    "model_type = 'gru'\n",
    "size = 64\n",
    "num_layers = 2\n",
    "drop_frac = 0.5\n",
    "lr = 0.001\n",
    "nb_epoch = 100\n",
    "batch_size = 100\n",
    "loss = 'mse'\n",
    "sim_type = 'survey_lcs'\n",
    "\n",
    "model_dict = {'gru': uneven_gru_autoencoder}\n",
    "X = pad_sequences(X_list, value=-1., dtype='float')\n",
    "model = model_dict[model_type](input_len=X.shape[-1], aux_input_len=2, n_step=X.shape[1],\n",
    "                               size=size, num_layers=num_layers, drop_frac=drop_frac)\n",
    "                                    \n",
    "run = \"{}_{:03d}_x{}_{:1.0e}_drop{}\".format(model_type, size, num_layers, lr,\n",
    "                                            int(100 * drop_frac)).replace('e-', 'm')\n",
    "if 'conv' in run:\n",
    "    run += '_f{}'.format(nfilter)\n",
    "\n",
    "history = ku.train_and_log({'main_input': X, 'aux_input': X[:, [0, 2]]}, X[:, 1:2],\n",
    "                            run, model, lr=lr, nb_epoch=nb_epoch, batch_size=batch_size,\n",
    "                           loss=loss, sim_type=sim_type)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
