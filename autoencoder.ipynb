{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = 9, 6\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "from keras import backend as K\n",
    "import sample_data\n",
    "%run autoencoder.py 64 4 0.25 --no_train --uneven --model_type conv --sigma 0.5 --lr 5e-4 --sim_type autoencoder/uneven/noise0.5 --filter_length 7 --nb_epoch 10 --batch_norm\n",
    "Y = sample_data.phase_to_sin_cos(Y)\n",
    "train = np.arange(args.N_train)\n",
    "test = args.N_train + np.arange(args.N_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from argparse import Namespace\n",
    "args = Namespace(sim_type='test', batch_size=10, embedding=32, gpu_frac=0.0, gpu_id=None, loss='mse', lr=0.002, m_max=32.0, model_type='gru', n_max=200, n_min=200, nb_epoch=100, num_epochs=10, num_layers=2, size=64)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import backend as K\n",
    "from keras.layers import (Input, Dense, TimeDistributed, Activation, LSTM, GRU,\n",
    "                          Dropout, merge, Reshape, Flatten, RepeatVector,\n",
    "                          Conv1D, AtrousConv1D, MaxPooling1D, SimpleRNN)\n",
    "try:\n",
    "    from keras.layers import PhasedLSTM\n",
    "except:\n",
    "    PhasedLSTM = None\n",
    "    print(\"Skipping PhasedLSTM...\")\n",
    "from keras.models import Model, Sequential\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import keras_util as ku\n",
    "from autoencoder import encoder, decoder\n",
    "from asas_full import preprocess\n",
    "\n",
    "X_raw = np.load('data/asas/n200.npy')\n",
    "model_type_dict = {'gru': GRU, 'lstm': LSTM, 'vanilla': SimpleRNN,\n",
    "                   'conv': Conv1D, 'atrous': AtrousConv1D, 'phased': PhasedLSTM}\n",
    "K.set_session(ku.limited_memory_session(args.gpu_frac, args.gpu_id))\n",
    "X, scale_params = preprocess(X_raw, args.m_max, None, True, True, True)\n",
    "main_input = Input(shape=(X.shape[1], X.shape[-1]), name='main_input')\n",
    "aux_input = Input(shape=(X.shape[1], X.shape[-1] - 1), name='aux_input')\n",
    "model_input = [main_input, aux_input]\n",
    "encode = encoder(main_input, layer=model_type_dict[args.model_type],\n",
    "                 output_size=args.embedding, **vars(args))\n",
    "decode = decoder(encode, layer=model_type_dict[args.model_type], n_step=X.shape[1],\n",
    "                 aux_input=aux_input, **vars(args))\n",
    "model = Model(model_input, decode)\n",
    "\n",
    "run = ku.get_run_id(**vars(args))\n",
    "\n",
    "sample_weight = (~np.isnan(X[:, :, -1])).astype('float')\n",
    "X[np.isnan(X)] = -1.\n",
    "history = ku.train_and_log({'main_input': X, 'aux_input': X[:, :, [0,]]}, X[:, :, 1:],\n",
    "                           run, model, sample_weight=sample_weight, **vars(args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "#K.set_learning_phase(0)\n",
    "%run asas_full.py 64 2 0.25 --no_train --model_type gru --lr 1e-3 --sim_type asas_full/n200 --nb_epoch 1 --n_min 200 --n_max 200 --m_max 32 --embedding 64\n",
    "# --filter_length 7 --batch_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing predictions"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "%%time\n",
    "pred = model.predict({'main_input': X, 'aux_input': X[:, :, [0,]]}, batch_size=500)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "inds = np.arange(1000)\n",
    "model.evaluate({'main_input': X[inds], 'aux_input': np.delete(X[inds], 1, axis=2)}, X_raw[inds, :, 1:2], batch_size=500)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "train = np.arange(args.N_train); test = args.N_train + np.arange(args.N_test)\n",
    "i = train[0] - 1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "i += 1\n",
    "if args.even:\n",
    "    t = np.linspace(0, 2 * np.pi, X.shape[1])\n",
    "    m = X[i, :, 0]\n",
    "    pred_i = model.predict(X[[i]])[0, :, 0]\n",
    "else:\n",
    "    inds = (X[i, :, 0] >= 0.)\n",
    "    t = X_raw[i, inds, 0]\n",
    "    m_raw = X_raw[i, inds, 1]\n",
    "    m = X[i, inds, 1]\n",
    "    pred_i = model.predict({'main_input': X[i:i+1], 'aux_input': X[i:i+1, :, [0,]]})[0, inds, 0]\n",
    "\n",
    "T = np.linspace(0, t.max(), 501)\n",
    "def sinusoid(p, A1, A2, b):\n",
    "    return lambda t: A1 * np.cos(2 * np.pi / p * t) + A2 * np.sin(2 * np.pi / p * t) + b\n",
    "\n",
    "plt.plot(T, sinusoid(*Y[i])(T))\n",
    "plt.plot(t, m, 'o')\n",
    "plt.plot(t, pred_i, 'o')\n",
    "\n",
    "#w_r, A_r, phi_r, b_r = pred_gru[i]\n",
    "#x_r = A_r * np.sin(2 * np.pi * w_r * t + phi_r) + b_r\n",
    "#plt.plot(t, x_r, '--')\n",
    "#plt.legend(['Noisy', 'Original'])\n",
    "plt.title(\"MSE: {}\".format(np.mean((m_raw - pred_i) ** 2)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "pred = model.predict({'main_input': X[:100], 'aux_input': np.delete(X[:100], 1, axis=2)}, batch_size=32)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "model.evaluate({'main_input': X, 'aux_input': np.delete(X, 1, axis=2)}, X[:, :, 1:2], batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#inds = ~np.isnan(X_raw[i, :, 0])\n",
    "inds = np.arange(args.n_min)\n",
    "i += 1\n",
    "#i = np.random.choice(inds)\n",
    "t = X_raw[i, inds, 0]\n",
    "m = X[i, inds, 1]\n",
    "#m = np.random.normal(size=len(t))\n",
    "e = X_raw[i, inds, 2]\n",
    "\n",
    "plt.errorbar(t, m, e, None, 'o');\n",
    "#plt.plot(t, pred[i], 'o');\n",
    "plt.errorbar(t, pred[i], None, None, 'o');\n",
    "\n",
    "#from gatspy.periodic import LombScargleFast\n",
    "#gat_resids = np.zeros(len(X))\n",
    "#model_gat = LombScargleFast(fit_period=True, optimizer_kwds={'period_range': (0.05 * (t.max() - t.min()), 0.95 * (t.max() - t.min())), 'quiet': True}, silence_warnings=True)\n",
    "#model_gat.fit(t, m)\n",
    "#print(model_gat.score(model_gat.best_period).item())\n",
    "\n",
    "#w_r, A_r, phi_r, b_r = pred_gru[i]\n",
    "#x_r = A_r * np.sin(2 * np.pi * w_r * t + phi_r) + b_r\n",
    "#plt.plot(t, x_r, '--')\n",
    "\n",
    "plt.legend(['Original', 'Reconstructed'])\n",
    "plt.title(\"MSE: {}, Var: {}\".format((np.mean((m - np.squeeze(pred[i])) ** 2)), np.var(m)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing training progress"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "log_files = glob.glob(os.path.join('keras_logs', 'autoencoder/uneven/noise0') + '/*.csv')\n",
    "logs = [pd.read_csv(f, usecols=['Wall time', 'Step', 'Value']) for f in log_files]\n",
    "for log, f in zip(logs, log_files):\n",
    "    label = f[(f.rfind('run_') + 4):f.rfind(',')] + ' ' + ('Validation' if 'val' in f else 'Training')\n",
    "    log.columns = [label if c == 'Value' else c for c in log.columns]\n",
    "    log['Wall time'] -= log['Wall time'].min()\n",
    "time_logs = pd.concat([l.set_index('Wall time').drop('Step', axis=1) for l in logs], axis=1)\n",
    "step_logs = pd.concat([l.set_index('Step').drop('Wall time', axis=1) for l in logs], axis=1)\n",
    "step_logs.head(10)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "step_logs.plot?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "colors = sns.color_palette(n_colors=int(len(step_logs.columns) / 2))\n",
    "for i, c in enumerate(step_logs.columns):\n",
    "    step_logs[c].dropna().plot(ax=ax[0], color=colors[int(i / 2)], legend=True, linestyle='-' if 'Training' in c else '--')\n",
    "    time_logs[c].dropna().plot(ax=ax[1], color=colors[int(i / 2)], legend=True, linestyle='-' if 'Training' in c else '--')\n",
    "ax[0].set_ylabel('Loss');\n",
    "ax[1].set_ylabel('Loss');\n",
    "ax[1].set_xlabel('Wall time (s)');"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Visualizing embeddings"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#%%time\n",
    "inds = np.arange(args.N_train, args.N_train + args.N_test)\n",
    "encode_layer = [l for l in model.layers if l.name == 'encoding'][0]\n",
    "if args.even:\n",
    "    encode = K.function([model.layers[0].input], [encode_layer.output])\n",
    "    encoding, = encode([X[inds]])\n",
    "else:\n",
    "    inputs = [l for l in model.layers if 'Input' in str(l)]\n",
    "    encode = K.function([inputs[0].input, inputs[1].input], [encode_layer.output])\n",
    "    encoding, = encode([X[inds], X[inds, :, 0:1]])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "np.mean((m - pred_i) ** 2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "S = np.corrcoef(encoding, Y[:encoding.shape[0]], rowvar=0)[:8, 8:]\n",
    "print(pd.DataFrame(S))\n",
    "plt.imshow(S, cmap='viridis', interpolation='none')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "sns.jointplot(encoding[:, 5], Y[:encoding.shape[0], 0], kind='hex')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "sns.jointplot(encoding[:, 1], Y[:encoding.shape[0], 1], kind='hex')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "sns.jointplot(encoding[:, 5], Y[:encoding.shape[0], 2], kind='hex')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "sns.jointplot(encoding[:, 3], Y[:encoding.shape[0], 3], kind='hex')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=128)\n",
    "#model = ElasticNet()\n",
    "#model = SVR(kernel='rbf')\n",
    "\n",
    "model.fit(encoding, Y[:encoding.shape[0], 0])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "encoding_test = encode([X[test]])[0]\n",
    "Y_pred = model.predict(encoding_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#sns.jointplot(Y[test, 0], Y_pred[:, 0])\n",
    "sns.jointplot(Y[test, 0], Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cesium.datasets\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "data = cesium.datasets.fetch_asas_training()\n",
    "\n",
    "# Discard samples from classes w/ insufficient examples\n",
    "top_classes = ['Classical_Cepheid', 'Mira', 'RR_Lyrae_FM', 'W_Ursae_Maj']\n",
    "inds = np.where(np.in1d(data['classes'], top_classes))[0]\n",
    "data = {'times': [data['times'][i] for i in inds],\n",
    "        'measurements': [data['measurements'][i] for i in inds],\n",
    "        'errors': [data['errors'][i] for i in inds],\n",
    "        'classes': [data['classes'][i] for i in inds]\n",
    "       }\n",
    "\n",
    "X_list = [np.c_[t, m, e] for t, m, e in zip(data['times'], data['measurements'], data['errors'])]\n",
    "\n",
    "sub_array_list = [np.array_split(x, np.arange(args.n_max, len(x), step=args.n_max)) for x in X_list]\n",
    "sub_array_list = [[el for el in x if len(el) >= args.n_min] for x in sub_array_list]\n",
    "X_list = [el for x in sub_array_list for el in x]\n",
    "\n",
    "classnames, indices = np.unique(data['classes'], return_inverse=True)\n",
    "y = np.repeat(indices, [len(x) for x in sub_array_list])\n",
    "Y = to_categorical(y, len(classnames))\n",
    "\n",
    "X_raw = pad_sequences(X_list, value=np.nan, dtype='float', padding='post')\n",
    "X, scale_params = preprocess(X_raw, args.m_max)\n",
    "\n",
    "# Remove errors\n",
    "X = X[:, :, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lc = LightCurve.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encode_layer = [l for l in model.layers if l.name == 'encoding'][0]\n",
    "inputs = [l for l in model.layers if 'Input' in str(l)]\n",
    "encode = K.function([inputs[0].input, inputs[1].input], [encode_layer.output])\n",
    "encoding, = encode([X, X[:, :, 0:1]])\n",
    "encoding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inds = ~np.isnan(X_raw[i, :, 0])\n",
    "#inds = np.arange(args.n_min)\n",
    "i += 1\n",
    "#i = np.random.choice(inds)\n",
    "t = X_raw[i, inds, 0]\n",
    "m = X[i, inds, 1]\n",
    "#m = np.random.normal(size=len(t))\n",
    "e = X_raw[i, inds, 2]\n",
    "\n",
    "plt.errorbar(t, m, e, None, 'o');\n",
    "#plt.plot(t, pred[i], 'o');\n",
    "#plt.errorbar(t, pred[i], None, None, 'o');\n",
    "\n",
    "from gatspy.periodic import LombScargleFast\n",
    "gat_resids = np.zeros(len(X))\n",
    "model_gat = LombScargleFast(fit_period=True, optimizer_kwds={'period_range': (0.001 * (t.max() - t.min()), 0.95 * (t.max() - t.min())), 'quiet': True}, silence_warnings=True)\n",
    "model_gat.fit(t, m)\n",
    "print(\"Best period: {} (Score: {})\".format(model_gat.best_period, model_gat.score(model_gat.best_period).item()))\n",
    "\n",
    "#w_r, A_r, phi_r, b_r = pred_gru[i]\n",
    "#x_r = A_r * np.sin(2 * np.pi * w_r * t + phi_r) + b_r\n",
    "#plt.plot(t, x_r, '--')\n",
    "\n",
    "plt.legend(['Original'])\n",
    "plt.title(\"i={} ({})\".format(i, classnames[y[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "enc_train, enc_test, y_train, y_test = train_test_split(encoding, y, test_size=0.25, random_state=42)\n",
    "\n",
    "#asas_model = RandomForestClassifier(n_estimators=128)\n",
    "asas_model = GridSearchCV(RandomForestClassifier(), {'n_estimators': [100, 250], 'criterion': ['gini', 'entropy'], 'max_features': [0.1, 0.2, 0.3]})\n",
    "#asas_model = SVC()\n",
    "asas_model.fit(enc_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Training score: {}%\".format(100 * asas_model.score(enc_train, y_train)))\n",
    "print(\"Test score: {}%\".format(100 * asas_model.score(enc_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Light curve database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from io import StringIO\n",
    "\n",
    "import pandas as pd\n",
    "from gatspy.periodic import LombScargleFast\n",
    "\n",
    "from db_models import db, LightCurve\n",
    "\n",
    "LightCurve.delete().where(LightCurve.survey == \"ASAS\").execute()\n",
    "data_source = []\n",
    "for fname in glob.glob('./data/asas/*/*'):\n",
    "    with open(fname) as f:\n",
    "        dfs = [pd.read_csv(StringIO(chunk), comment='#', delim_whitespace=True) for chunk in f.read().split('#     ')[1:]]\n",
    "        if len(dfs) > 0:\n",
    "            df = pd.concat(dfs)[['HJD', 'MAG_0', 'MER_0', 'GRADE']].sort_values(by='HJD')\n",
    "            df = df[df.GRADE <= 'B']\n",
    "\n",
    "            data_source.append({'name': os.path.basename(fname), 'survey': 'ASAS', 'times': df.HJD.values, \n",
    "                                'measurements': df.MAG_0.values, 'errors': df.MER_0.values,\n",
    "#                                'best_period': model_gat.best_period, 'best_score': model_gat.score(model_gat.best_period).item()\n",
    "                               })\n",
    "            \n",
    "with db.atomic():\n",
    "    for idx in range(0, len(data_source), 100):\n",
    "        LightCurve.insert_many(data_source[idx:idx + 100]).execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for lc in LightCurve.select().where(LightCurve.best_score >> None):\n",
    "    model_gat = LombScargleFast(fit_period=True, optimizer_kwds={'period_range': (0.005 * (max(lc.times) - min(lc.times)), 0.95 * (max(lc.times) - min(lc.times))), 'quiet': True}, silence_warnings=True)\n",
    "    model_gat.fit(lc.times, lc.measurements, lc.errors)\n",
    "    lc.best_period = model_gat.best_period\n",
    "    lc.best_score = model_gat.score(model_gat.best_period).item()\n",
    "    lc.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from db_models import LightCurve\n",
    "\n",
    "bigmacc = pd.read_csv('data/asas/bigmacc.txt', delimiter='\\t')\n",
    "with db.atomic():\n",
    "    for i, row in bigmacc.iterrows():\n",
    "        try:\n",
    "            lc = LightCurve.get(name=row.ASAS_ID)\n",
    "            lc.label = row.CLASS\n",
    "            lc.save()\n",
    "        except LightCurve.DoesNotExist:\n",
    "            pass"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
